# ğŸ§  GraphMind - Hybrid Vector + Graph Database

**A hackathon project for efficient AI retrieval combining semantic similarity (vectors) with relational knowledge (graphs)**

## ğŸ¯ Project Overview

GraphMind is a hybrid database system that combines:
- **Vector Search** (ChromaDB) - Semantic similarity using embeddings
- **Graph Search** (NetworkX) - Relational traversal and connections
- **Hybrid Search** - Intelligent combination of both approaches

Built for the Devfolio Problem Statement: "Vector + Graph Native Database for Efficient AI Retrieval"

## âœ¨ Key Features

- âœ… **Dual Storage**: ChromaDB (vectors) + NetworkX (graph)
- âœ… **Full CRUD Operations**: Create, Read, Update, Delete nodes and edges
- âœ… **3 Search Modes**: Vector-only, Graph-only, Hybrid
- âœ… **Separate Search Endpoints**: `/search/vector`, `/search/graph`, `/search/hybrid`
- âœ… **Graph Traversal**: BFS traversal with depth control
- âœ… **File Ingestion**: Upload and parse text, PDF, XML, JSON, CSV files
- âœ… **Entity Extraction**: Automatic entity detection and graph building
- âœ… **Semantic Edges**: Automatic similarity-based connections
- âœ… **PageRank Centrality**: Identify important nodes
- âœ… **LLM Integration**: Gemini API for natural language answers
- âœ… **Web Interface**: Complete UI with graph visualization
- âœ… **Comparison Tool**: Side-by-side evaluation of search methods
- âœ… **Multi-hop Reasoning**: Find connections through multiple graph hops
- âœ… **Relationship-weighted Search**: Weight graph scores by relationship type
- âœ… **Pagination & Filtering**: Graph endpoint supports pagination and node type filtering

## ğŸš€ Quick Start

### 1. Setup

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Start Server

```bash
uvicorn backend.main:app --reload
```

### 3. Access Application

- **Web UI**: http://127.0.0.1:8000/
- **API Docs**: http://127.0.0.1:8000/docs
- **Health Check**: http://127.0.0.1:8000/health

## ğŸ“‹ Usage

### Upload Files

1. Go to the **Upload** tab
2. Drag & drop or select files (txt, pdf, xml, json, csv)
3. Select file type
4. Files are automatically parsed, chunked, and stored

### Search

1. Go to the **Search** tab
2. Enter your query
3. Select search mode:
   - **Hybrid** (Recommended) - Combines vector + graph
   - **Vector Only** - Semantic similarity
   - **Graph Only** - Relational traversal
4. View results with AI-generated answer

### Compare Methods

1. Go to the **Compare** tab
2. Enter a query
3. See side-by-side comparison of all three methods
4. View precision metrics and winner
5. Get LLM-generated summary

### Visualize Graph

1. Go to the **Graph** tab
2. See interactive visualization of your knowledge graph
3. Nodes represent concepts/entities
4. Edges show relationships

### Manage Nodes

1. Go to the **Nodes** tab
2. Enter a node ID to view details
3. See all relationships (incoming and outgoing)
4. Edit node content or metadata
5. Delete node (removes all connected edges)

### Graph Traversal

1. Go to the **Traversal** tab
2. Enter a start node ID
3. Adjust depth slider (1-10)
4. Set max nodes to return
5. View traversal results with paths
6. See visualization of traversal paths

## ğŸ”§ API Endpoints

### Core Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Web interface |
| `/health` | GET | Health check with system status |
| `/stats` | GET | Database statistics |

### Node CRUD

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/nodes` | POST | Create a node with text, metadata, and embedding |
| `/nodes/{id}` | GET | Get node by ID with all relationships |
| `/nodes/{id}` | PUT | Update node content and/or metadata |
| `/nodes/{id}` | DELETE | Delete node and all associated edges |

### Edge CRUD

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/edges` | POST | Create a relationship: {source, target, type, weight} |
| `/edges/{edge_id}` | GET | Get edge details (or use ?source_id=X&target_id=Y) |

### Search Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/search` | POST | Unified search (vector/graph/hybrid mode) |
| `/search/vector` | POST | Vector-only search: {query_text, top_k} |
| `/search/graph` | GET | Graph traversal: ?start_id=X&depth=3&max_nodes=100 |
| `/search/hybrid` | POST | Hybrid search: {query_text, vector_weight, graph_weight, top_k} |
| `/search/multi-hop` | POST | Multi-hop reasoning query |
| `/compare` | POST | Compare all search methods side-by-side |

### Graph & Ingestion

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/graph` | GET | Get full graph snapshot (with pagination & filtering) |
| `/ingest` | POST | Upload and process file |

## ğŸ—ï¸ Architecture

```
Input File
    â†“
Parser (MultiFormatParser)
    â†“
Chunking + Entity Extraction
    â†“
Parallel Processing
    â”œâ†’ ChromaDB (Vector Embeddings)
    â””â†’ NetworkX (Graph Structure)
    â†“
Merge Algorithm
    â”œâ†’ PageRank (Centrality)
    â””â†’ Semantic Edges (Similarity > 0.7)
    â†“
Query
    â”œâ†’ Vector Search (Cosine Similarity)
    â”œâ†’ Graph Search (BFS Traversal)
    â””â†’ Hybrid Search (Weighted Combination)
    â†“
LLM Processing (Gemini)
    â†“
Structured Answer
```

## ğŸ§® Hybrid Scoring Algorithm

```python
# Normalize scores to [0, 1]
vector_score = normalize(cosine_similarity(query, node))
graph_score = normalize(1 / (distance + 1))

# Weighted combination
final_score = Î± * vector_score + (1 - Î±) * graph_score

# Default: Î± = 0.6 (60% vector, 40% graph)
```

## ğŸ“¦ Tech Stack

- **Backend**: FastAPI (async, auto-docs)
- **Vector DB**: ChromaDB (embedded, persistent)
- **Graph DB**: NetworkX (pure Python)
- **Embeddings**: SentenceTransformers (all-MiniLM-L6-v2)
- **LLM**: Google Gemini API
- **Frontend**: HTML + Cytoscape.js
- **File Parsing**: PyPDF2, xmltodict, csv

## ğŸ¯ Demo Use Case

**Personal Knowledge Graph for AI Research**

- Nodes: Concepts (ML, NLP), Papers, Techniques, Applications
- Edges: Relationships, citations, applications
- Query: "Healthcare AI"
- Result: Found through both semantic similarity AND graph connections to "Medical Imaging"

## ğŸ“Š Stretch Goals Implemented

- âœ… **Multi-hop Reasoning**: `/search/multi-hop` endpoint finds connections through multiple graph hops
- âœ… **Relationship-weighted Search**: Enhanced hybrid search with relationship type weighting
- âœ… **Pagination & Filtering**: Graph endpoint supports pagination (`page`, `limit`) and filtering (`node_type`)
- âœ… **Graph Traversal**: Depth-controlled BFS traversal with path visualization

## ğŸ¯ Devfolio Requirements Compliance

### Required Features âœ…

- âœ… Vector storage with cosine similarity search
- âœ… Graph storage with nodes, edges, and metadata
- âœ… Hybrid retrieval merging vector similarity + graph adjacency
- âœ… API endpoints for CRUD operations
- âœ… Vector search endpoint (`POST /search/vector`)
- âœ… Graph traversal endpoint (`GET /search/graph`)
- âœ… Hybrid search endpoint (`POST /search/hybrid`)
- âœ… Simple scoring/ranking mechanism for hybrid results
- âœ… Embeddings pipeline (SentenceTransformers)
- âœ… Local persistence (ChromaDB + NetworkX)

### Stretch Goals âœ…

- âœ… Multi-hop reasoning query
- âœ… Relationship-weighted search
- âœ… Pagination and filtering

## ğŸ“Š Evaluation Criteria

âœ… **Working CRUD + Search** (20/50 pts)
âœ… **Hybrid Logic Clarity** (10/50 pts)
âœ… **Real-world Demo** (30/100 pts)
âœ… **Hybrid Effectiveness Proof** (25/100 pts)

## ğŸ” Verification

Run the verification script:

```bash
python verify_project.py
```

This checks:
- All imports
- Configuration
- Storage operations
- File parsing
- Ingestion pipeline
- LLM processor
- API endpoints

## ğŸ› ï¸ Configuration

Edit `backend/config.py` or create `.env`:

```python
LLM_PROVIDER = "gemini"  # or "mock"
GEMINI_API_KEY = "your-key-here"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
HYBRID_ALPHA = 0.6  # Vector weight
```

## ğŸ“ Project Structure

```
graphmind/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ config.py          # Settings
â”‚   â”œâ”€â”€ models.py          # Pydantic models
â”‚   â”œâ”€â”€ storage.py         # ChromaDB + NetworkX
â”‚   â”œâ”€â”€ parsers.py         # File parsing
â”‚   â”œâ”€â”€ ingestion.py       # Parallel pipeline
â”‚   â”œâ”€â”€ llm_processor.py   # Gemini integration
â”‚   â”œâ”€â”€ evaluation.py      # Comparison logic
â”‚   â””â”€â”€ main.py            # FastAPI app
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html         # Web UI
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/           # Uploaded files
â”‚   â””â”€â”€ chroma/            # ChromaDB storage
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš¨ Troubleshooting

### Server won't start
- Check port 8000 is available
- Verify virtual environment is activated
- Run `pip install -r requirements.txt`

### Import errors
- Ensure you're in project root
- Activate virtual environment
- Check Python version (3.8+)

### LLM not working
- Verify Gemini API key in `config.py`
- Check internet connection
- Fallback to mock LLM if needed

### Graph not showing
- Upload some files first
- Check browser console for errors
- Verify Cytoscape.js is loading

## ğŸ‰ Features Completed

- [x] Dual storage (ChromaDB + NetworkX)
- [x] Vector search
- [x] Graph traversal search
- [x] Hybrid search algorithm
- [x] Parallel file ingestion
- [x] Entity extraction
- [x] Semantic similarity edges
- [x] PageRank centrality
- [x] Gemini LLM integration
- [x] Web interface
- [x] Graph visualization
- [x] Comparison tool
- [x] CRUD APIs

## ğŸ“„ License

MIT License - Hackathon Project

## ğŸ™ Acknowledgments

- ChromaDB for vector storage
- NetworkX for graph operations
- FastAPI for the web framework
- Google Gemini for LLM capabilities
- Cytoscape.js for graph visualization

---

**Built for Devfolio Hackathon - 12 Hour Challenge**

